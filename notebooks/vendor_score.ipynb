{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075b3ec7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'views'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bekuman\\Desktop\\E-commerce-Data-Extractor\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'views'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Execute the function\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     result = \u001b[43mgenerate_vendor_scorecard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     87\u001b[39m         \u001b[38;5;28mprint\u001b[39m(result.head())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mgenerate_vendor_scorecard\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     42\u001b[39m avg_views = group[\u001b[33m'\u001b[39m\u001b[33mviews\u001b[39m\u001b[33m'\u001b[39m].mean() \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mviews\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m group \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group[\u001b[33m'\u001b[39m\u001b[33mviews\u001b[39m\u001b[33m'\u001b[39m].isnull().all() \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Top post info\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m top_post = group.loc[group[\u001b[33m'\u001b[39m\u001b[33mviews\u001b[39m\u001b[33m'\u001b[39m].idxmax()] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mviews\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.isnull().all() \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m     46\u001b[39m top_product = top_post.get(\u001b[33m'\u001b[39m\u001b[33mproduct\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     47\u001b[39m top_price = top_post.get(\u001b[33m'\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bekuman\\Desktop\\E-commerce-Data-Extractor\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bekuman\\Desktop\\E-commerce-Data-Extractor\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'views'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_vendor_scorecard():\n",
    "    # === STEP 1: Load Data ===\n",
    "    try:\n",
    "        df = pd.read_csv(\"../data/cleaned_message.csv\")  \n",
    "        ner_df = pd.read_csv(\"../data/tokenized_messages.csv\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data files: {e}\")\n",
    "        return None\n",
    "\n",
    "    # === STEP 2: Merge Data ===\n",
    "    # Ensure we have required columns\n",
    "    required_columns = {'ID', 'Date'}\n",
    "    if not required_columns.issubset(df.columns) or not required_columns.issubset(ner_df.columns):\n",
    "        print(\"Missing required columns in input data\")\n",
    "        return None\n",
    "\n",
    "    merged = pd.merge(df, ner_df, on=['ID'], how='left', suffixes=('', '_ner'))\n",
    "    \n",
    "    # Convert and clean date\n",
    "    merged['Date'] = pd.to_datetime(merged['Date'], errors='coerce')\n",
    "    merged = merged.dropna(subset=['Date'])\n",
    "    \n",
    "    if merged.empty:\n",
    "        print(\"No valid data after merging and cleaning\")\n",
    "        return None\n",
    "\n",
    "    # === STEP 3: Compute Metrics Per Vendor ===\n",
    "    vendor_scores = []\n",
    "\n",
    "    for vendor, group in merged.groupby('ID'):\n",
    "        group = group.sort_values('Date')\n",
    "        \n",
    "        # Activity & Consistency\n",
    "        time_span = (group['Date'].max() - group['Date'].min()).days\n",
    "        days_range = time_span if time_span > 0 else 1  # avoid division by zero\n",
    "        posts_per_week = round((len(group) / days_range) * 7, 2)\n",
    "\n",
    "        # Engagement (handle missing views)\n",
    "        avg_views = group['views'].mean() if 'views' in group and not group['views'].isnull().all() else 0\n",
    "        \n",
    "        # Top post info\n",
    "        top_post = group.loc[group['views'].idxmax()] if not group['views'].isnull().all() else {}\n",
    "        top_product = top_post.get('product', 'N/A')\n",
    "        top_price = top_post.get('price', 'N/A')\n",
    "\n",
    "        # Business Profile (price analysis)\n",
    "        prices = pd.to_numeric(group['price'], errors='coerce')\n",
    "        valid_prices = prices.dropna()\n",
    "        avg_price = valid_prices.mean() if not valid_prices.empty else 0\n",
    "\n",
    "        # Normalized scores (0-100 range)\n",
    "        views_score = min(avg_views / 1000 * 100, 100)  # assuming 1000 views = max score\n",
    "        activity_score = min(posts_per_week * 10, 100)   # assuming 10 posts/week = max score\n",
    "        \n",
    "        # Weighted lending score\n",
    "        lending_score = (views_score * 0.6) + (activity_score * 0.4)\n",
    "\n",
    "        vendor_scores.append({\n",
    "            \"Vendor ID\": vendor,\n",
    "            \"Avg. Views/Post\": round(avg_views, 2),\n",
    "            \"Posts/Week\": posts_per_week,\n",
    "            \"Avg. Price (ETB)\": round(avg_price, 2) if avg_price else \"N/A\",\n",
    "            \"Top Product\": top_product,\n",
    "            \"Top Price\": top_price,\n",
    "            \"Lending Score\": round(lending_score, 1)  # one decimal place\n",
    "        })\n",
    "\n",
    "    # === STEP 4: Output Scorecard ===\n",
    "    scorecard_df = pd.DataFrame(vendor_scores)\n",
    "    scorecard_df = scorecard_df.sort_values(\"Lending Score\", ascending=False)\n",
    "    \n",
    "    try:\n",
    "        scorecard_df.to_csv(\"../data/vendor_scorecard.csv\", index=False)\n",
    "        print(\"Successfully generated vendor scorecard\")\n",
    "        return scorecard_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving scorecard: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute the function\n",
    "if __name__ == \"__main__\":\n",
    "    result = generate_vendor_scorecard()\n",
    "    if result is not None:\n",
    "        print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bda2ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bekuman\\Desktop\\E-commerce-Data-Extractor\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Execute\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     scorecard = \u001b[43mgenerate_scorecard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Top 5 Vendors ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mprint\u001b[39m(scorecard.head().to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mgenerate_scorecard\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Merge and clean data\u001b[39;00m\n\u001b[32m     28\u001b[39m merged = pd.merge(posts_df, ner_df, on=\u001b[33m\"\u001b[39m\u001b[33mID\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m merged[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(\u001b[43mmerged\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m merged = merged.dropna(subset=[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mviews\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Calculate metrics per vendor\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bekuman\\Desktop\\E-commerce-Data-Extractor\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bekuman\\Desktop\\E-commerce-Data-Extractor\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants (adjust weights based on business priorities)\n",
    "VIEWS_WEIGHT = 0.5      # Engagement importance\n",
    "FREQUENCY_WEIGHT = 0.3  # Activity importance\n",
    "PRICE_WEIGHT = 0.2      # Business profile importance\n",
    "\n",
    "def calculate_lending_score(avg_views, posts_per_week, avg_price, max_views=5000, max_freq=20, max_price=10000):\n",
    "    \"\"\"Normalize metrics to 0-100 scale and compute weighted score.\"\"\"\n",
    "    views_norm = min(avg_views / max_views * 100, 100)\n",
    "    freq_norm = min(posts_per_week / max_freq * 100, 100)\n",
    "    price_norm = min(avg_price / max_price * 100, 100) if avg_price > 0 else 0\n",
    "    \n",
    "    return (views_norm * VIEWS_WEIGHT) + (freq_norm * FREQUENCY_WEIGHT) + (price_norm * PRICE_WEIGHT)\n",
    "\n",
    "def generate_scorecard():\n",
    "    # Load data\n",
    "    try:\n",
    "        posts_df = pd.read_csv(\"../data/cleaned_message.csv\")  # Columns: ID, Date, message, views\n",
    "        ner_df = pd.read_csv(\"../data/tokenized_messages.csv\")  # Columns: ID, product, price\n",
    "    except Exception as e:\n",
    "        print(f\"Data loading failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Merge and clean data\n",
    "    merged = pd.merge(posts_df, ner_df, on=\"ID\", how=\"left\")\n",
    "    merged[\"Date\"] = pd.to_datetime(merged[\"Date\"], errors=\"coerce\")\n",
    "    merged = merged.dropna(subset=[\"Date\", \"views\"])\n",
    "    \n",
    "    # Calculate metrics per vendor\n",
    "    metrics = []\n",
    "    for vendor_id, group in merged.groupby(\"ID\"):\n",
    "        group = group.sort_values(\"Date\")\n",
    "        \n",
    "        # Activity & Consistency\n",
    "        days_active = (group[\"Date\"].max() - group[\"Date\"].min()).days\n",
    "        posts_per_week = (len(group) / max(days_active, 1)) * 7  # Prevent division by zero\n",
    "        \n",
    "        # Engagement\n",
    "        avg_views = group[\"views\"].mean()\n",
    "        top_post = group.loc[group[\"views\"].idxmax()]\n",
    "        \n",
    "        # Business Profile\n",
    "        prices = pd.to_numeric(group[\"price\"], errors=\"coerce\").dropna()\n",
    "        avg_price = prices.mean() if not prices.empty else 0\n",
    "        \n",
    "        # Calculate Lending Score\n",
    "        score = calculate_lending_score(avg_views, posts_per_week, avg_price)\n",
    "        \n",
    "        metrics.append({\n",
    "            \"Vendor ID\": vendor_id,\n",
    "            \"Avg. Views/Post\": round(avg_views),\n",
    "            \"Posts/Week\": round(posts_per_week, 1),\n",
    "            \"Avg. Price (ETB)\": round(avg_price) if avg_price > 0 else \"N/A\",\n",
    "            \"Top Product\": top_post.get(\"product\", \"N/A\"),\n",
    "            \"Top Product Views\": top_post[\"views\"],\n",
    "            \"Lending Score\": round(score, 1)  # 0-100 scale\n",
    "        })\n",
    "\n",
    "    # Generate and save scorecard\n",
    "    scorecard = pd.DataFrame(metrics).sort_values(\"Lending Score\", ascending=False)\n",
    "    scorecard.to_csv(\"../data/vendor_scorecard.csv\", index=False)\n",
    "    return scorecard\n",
    "\n",
    "# Execute\n",
    "if __name__ == \"__main__\":\n",
    "    scorecard = generate_scorecard()\n",
    "    print(\"\\n=== Top 5 Vendors ===\")\n",
    "    print(scorecard.head().to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
